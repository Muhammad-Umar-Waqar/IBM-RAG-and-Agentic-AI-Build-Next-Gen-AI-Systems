<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<style>
    body{
        padding: 20px 0px 20px 0px;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
    

    }
    a{
        text-decoration: none;
        color: rgba(0, 0, 0, 0.658);
        background: wheat;
        padding: 10px 20px 10px 20px;
        margin-top: 10px;
        border-radius: 3px;
    }
    .code-sec{
        width:90%;
        margin: 10px 0 10px 0px;
        padding: 10px;
        border: 1px solid rgb(83, 83, 83);
        border-radius: 20px;
    }


  pre {
  background-color: #f4f4f4;
  overflow-x: auto;
  padding: 10px;
  border-radius: 10px;
  width: 100%;
  box-sizing: border-box;
  white-space: pre-wrap; /* ✅ wraps long lines */
  word-break: break-word; /* ✅ breaks long URLs or words */
}

code {
  font-family: Consolas, 'Courier New', monospace;
  font-size: 14px;
  white-space: pre-wrap; /* wraps long lines */
  word-wrap: break-word;
}



</style>
<body>
    <a href="https://labs.cognitiveclass.ai/v2/tools/cloud-ide?ulid=ulid-bcac0f0d8d75058d058bdbb7170a12f391532b4a">QA Chatbot Lab Link</a>
    <a href="https://author.skills.network/courses/4529/labs/11858">QA Chatbot</a>
    
     <div class="code-sec">
         <h1>Code:</h1>
        <pre>
         <code>
            pip install virtualenv
            virtualenv my_env # create a virtual environment named my_env
            source my_env/bin/activate # activate my_env
         </code>
        </pre>
        </div>
    

         <div class="code-sec">
         <h1>Code:</h1>
        <pre>
         <code>
            # installing necessary packages in my_env
            python3.11 -m pip install \
            gradio==4.44.0 \
            ibm-watsonx-ai==1.1.2  \
            langchain==0.2.11 \
            langchain-community==0.2.10 \
            langchain-ibm==0.1.11 \
            chromadb==0.4.24 \
            pypdf==4.3.1 \
            pydantic==2.9.1
            </code>
        </pre>
        </div>

    
    <div class="code-sec">
        <h1>Code:</h1>
        <pre>
            <code>
            from ibm_watsonx_ai.foundation_models import ModelInference
            from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams
            from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames
            from ibm_watsonx_ai import Credentials
            from langchain_ibm import WatsonxLLM, WatsonxEmbeddings
            from langchain.text_splitter import RecursiveCharacterTextSplitter
            from langchain_community.vectorstores import Chroma
            from langchain_community.document_loaders import PyPDFLoader
            from langchain.chains import RetrievalQA



            import gradio as gr

            # You can use this section to suppress warnings generated by your code:
            def warn(*args, **kwargs):
                pass
            import warnings
            warnings.warn = warn
            warnings.filterwarnings('ignore')


            def tiktoken_len(text):
                return len(text)


            def get_llm():
                model_id='ibm/granite-3-2-8b-instruct'
                parameters = {
                    GenParams.MAX_NEW_TOKENS: 256,
                    GenParams.TEMPERATURE:  0.5
                } 
                project_id = "skills-network"
                watsonx_llm = WatsonxLLM(
                    model_id= model_id,
                    url="https://us-south.ml.cloud.ibm.com",
                    project_id=project_id,
                    params=parameters
                )

                return watsonx_llm


            def document_loader(file):
                loader = PyPDFLoader(file.name)
                loaded_document = loader.load()
                return loaded_document


            def text_splitter(data):
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=100, 
                    chunk_overlap=0,
                    length_function=tiktoken_len,
                )

                chunks = text_splitter.split_documents(data)
                return chunks


            ## Embedding model
            def watsonx_embedding():
                embed_params = {
                        EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 150,  
                    }
                
                watsonx_embedding = WatsonxEmbeddings(
                    model_id="ibm/slate-30m-english-rtrvr",
                    url="https://us-south.ml.cloud.ibm.com", 
                    project_id="skills-network",
                    params=embed_params,
                )

                return watsonx_embedding


            def vector_database(chunks):
                embedding_model = watsonx_embedding()
                vectordb = Chroma.from_documents(
                    chunks,
                    embedding_model
                    )
                return vectordb

            ## Retriever
            def retriever(file):
                splits = document_loader(file)
                chunks = text_splitter(splits)
                vectordb = vector_database(chunks)
                retriever = vectordb.as_retriever()
                return retriever


                ## QA Chain
            def retriever_qa(file, query):
                llm = get_llm()
                retriever_obj = retriever(file)
                qa = RetrievalQA.from_chain_type(llm=llm, 
                                                chain_type="stuff", 
                                                retriever=retriever_obj, 
                                                return_source_documents=True)
                response = qa.invoke(query)
                return response['result']

            gr.Interface(
                fn=retriever_qa,
                inputs = [ 
                    gr.File(
                        label = "Upload PDF File",
                        file_count="single",
                        file_types=[".pdf"],
                        type= "filepath"
                    ),
                    gr.Textbox(
                        label="Input Query",
                        lines = 2,
                        placeholder="Type your question here"
                    )
                ],
                outputs = gr.Textbox(label="Answer"),
                title="QA BOT",
                description="Upload a PDF document and ask any question. The chatbot will try to answer using the provided document."
            ).launch()
            </code>
        </pre>
    </div>
</body>
</html>


